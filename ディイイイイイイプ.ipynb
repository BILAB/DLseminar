{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/higuchiitto/pyworks/研究室/deep_learning_seminer/simdata/'\n",
    "\n",
    "train = pd.read_csv(path + 'saturn_data_train.csv', header=None)\n",
    "test = pd.read_csv(path + 'saturn_data_eval.csv', header=None)\n",
    "\n",
    "train_data = np.array(train.iloc[:, 1:])\n",
    "train_label = np.array(train.iloc[:, 0]).astype(int)\n",
    "\n",
    "test_data = np.array(test.iloc[:, 1:])\n",
    "test_label = np.array(test.iloc[:, 0]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "log_dir = '../log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#　Heの初期値\n",
    "initializer = tf.random_normal_initializer(mean=0,\n",
    "                                                                       stddev=(2/BATCH_SIZE)**0.5)\n",
    "\n",
    "def inference(data_ph):\n",
    "    with tf.variable_scope('fc1') as scope:\n",
    "        weights = tf.get_variable(name='weights',\n",
    "                                                     shape=(2, 32),\n",
    "                                                     initializer=initializer)#.initialized_value()\n",
    "        biases = tf.get_variable(name='biases',\n",
    "                                                   shape=(32),\n",
    "                                                   initializer=tf.zeros_initializer())#.initialized_value()\n",
    "        product = tf.matmul(data_ph, weights)\n",
    "        fc1 = tf.nn.relu(tf.nn.bias_add(product, biases))\n",
    "        \n",
    "    with tf.variable_scope('fc2') as scope:\n",
    "        weights = tf.get_variable(name='weights',\n",
    "                                                    shape=(32, 2),\n",
    "                                                    initializer=initializer)#.initialized_value()\n",
    "        biases = tf.get_variable(name='biases',\n",
    "                                                   shape=(2),\n",
    "                                                   initializer=tf.zeros_initializer())#.initialized_value()\n",
    "        product = tf.matmul(fc1, weights)\n",
    "        logits = tf.nn.relu(tf.nn.bias_add(product, biases))\n",
    "        \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _loss(logits, labels):\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels, name='xentropy_per_sample')\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy, name='xentropy')\n",
    "    return cross_entropy_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(loss, global_step):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "    gradients = optimizer.compute_gradients(loss)\n",
    "    train_op = optimizer.apply_gradients(gradients, global_step=global_step)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      " trainning_precision: 0.64\n",
      " test_precision: 0.61\n",
      "Step 2:\n",
      " trainning_precision: 0.73\n",
      " test_precision: 0.71\n",
      "Step 3:\n",
      " trainning_precision: 0.81\n",
      " test_precision: 0.75\n",
      "Step 4:\n",
      " trainning_precision: 0.83\n",
      " test_precision: 0.85\n",
      "Step 5:\n",
      " trainning_precision: 0.91\n",
      " test_precision: 0.9\n",
      "Step 6:\n",
      " trainning_precision: 0.94\n",
      " test_precision: 0.94\n",
      "Step 7:\n",
      " trainning_precision: 0.99\n",
      " test_precision: 0.97\n",
      "Step 8:\n",
      " trainning_precision: 0.99\n",
      " test_precision: 0.97\n",
      "Step 9:\n",
      " trainning_precision: 1.0\n",
      " test_precision: 1.0\n",
      "Perfect precision was completed!!\n"
     ]
    }
   ],
   "source": [
    "global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "train_loss = tf.Variable(0.0, trainable=False, name='train_loss')\n",
    "train_precision = tf.Variable(0.0, trainable=False, name='train_precision')\n",
    "test_loss = tf.Variable(0.0, trainable=False, name='test_loss')\n",
    "test_precision = tf.Variable(0.0, trainable=False, name='test_precision')\n",
    "\n",
    "train_loss_summary = tf.summary.scalar('loss/train', train_loss)\n",
    "train_precision_summary = tf.summary.scalar('precision/train', train_precision)\n",
    "test_loss_summary = tf.summary.scalar('loss/test', test_loss)\n",
    "test_precision_summary = tf.summary.scalar('precision/test', test_precision)\n",
    "    \n",
    "data_ph = tf.placeholder(tf.float32, shape=(None, 2), name='input_placeholder')\n",
    "label_ph = tf.placeholder(tf.int32, shape=(None), name='label_placeholder')\n",
    "\n",
    "logits = inference(data_ph)\n",
    "loss = _loss(logits, label_ph)\n",
    "train_op = train(loss, global_step)\n",
    "eval_correct = tf.nn.in_top_k(logits, label_ph, 1)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "end_flag = False\n",
    "\n",
    "with tf.Session() as sess:    \n",
    "    sess.run(init)\n",
    "    \n",
    "    summary_writer = tf.summary.FileWriter(log_dir, sess.graph)\n",
    "    for step in range(100):\n",
    "        shuffle = np.random.permutation(500)\n",
    "        for i in range(5):\n",
    "            start = BATCH_SIZE*i\n",
    "            end = BATCH_SIZE*(i+1)\n",
    "            \n",
    "            shuffled_data = train_data[start:end]\n",
    "            shuffled_label = train_label[start:end]\n",
    "            \n",
    "            _, loss_value, correction = sess.run([train_op, loss, eval_correct], feed_dict={data_ph : shuffled_data,\n",
    "                                                                                            label_ph : shuffled_label})\n",
    "\n",
    "            if i == 4:\n",
    "                sess.run(train_loss.assign(loss_value))\n",
    "                sess.run(train_precision.assign(correction.sum()/100))\n",
    "                \n",
    "                summary_str_1, summary_str_2= sess.run([train_loss_summary, train_precision_summary])\n",
    "                summary_writer.add_summary(summary_str_1, step)\n",
    "                summary_writer.add_summary(summary_str_2, step)\n",
    "                \n",
    "                print('Step {0}:\\n trainning_precision: {1}'.format(step+1,correction.sum()/100))\n",
    "                \n",
    "                loss_value, test_correction = sess.run([loss, eval_correct], \n",
    "                                                                         feed_dict={data_ph : test_data, label_ph : test_label})\n",
    "                sess.run(test_loss.assign(loss_value))\n",
    "                sess.run(test_precision.assign(test_correction.sum()/100))\n",
    "                \n",
    "                summary_str_3, summary_str_4 = sess.run([test_loss_summary, test_precision_summary])\n",
    "                summary_writer.add_summary(summary_str_3, step)\n",
    "                summary_writer.add_summary(summary_str_4, step)\n",
    "                \n",
    "                print(' test_precision: {}'.format(test_correction.sum()/100))\n",
    "                \n",
    "                if test_correction.sum() == 100:\n",
    "                    print('Perfect precision was completed!!')\n",
    "                    end_flag = True\n",
    "            if end_flag == True:\n",
    "                break\n",
    "        if end_flag == True:\n",
    "            summary_writer.close()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
